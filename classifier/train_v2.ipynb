{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying letters\n",
    "\n",
    "This notebook contains a training script for a classifier that can recognize a few letters from a bitmap.\n",
    "Version 2: uses data from the wand to validate (\"transfer learning\", if you will)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import numpy as np   # numpy==1.22.0 \n",
    "from matplotlib import pyplot\n",
    "# import tensorflow as tf\n",
    "# # from tensorflow.keras.models import Sequential\n",
    "# # from tensorflow.keras import layers\n",
    "# from tensorflow import keras\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential  # tf v 2.10\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "\n",
    "# import tensorflow_io as tfio  // package not working in windows =\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "# from tensorflow_addons import image\n",
    "import tensorflow_addons as tfa\n",
    "import pathlib\n",
    "import shutil\n",
    "from os import path\n",
    "from pathlib import Path\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dfbf34",
   "metadata": {},
   "source": [
    "create new dataset from wand drawn images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11540b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images collated and rotated\n"
     ]
    }
   ],
   "source": [
    "# first, copy all images of same class to single dir\n",
    "\n",
    "letter = 'M'     \n",
    "\n",
    "IMG_HEIGHT = 32 \n",
    "IMG_WIDTH =  IMG_HEIGHT\n",
    "RO_ANG = np.pi/3\n",
    "\n",
    "# img_res = tf.image.resize_bilinear(img_4d, (IMG_HEIGHT, IMG_WIDTH), align_corners=True)\n",
    "\n",
    "\n",
    "def moveWandFiles(source_folder:pathlib.Path, target_folder:pathlib.Path,letter):\n",
    "    target_folder= os.path.join(target_folder + letter )   \n",
    "    source_folder= os.path.join(source_folder + letter )   \n",
    "    Path(target_folder).mkdir(parents=True, exist_ok=True)\n",
    "    ii = 1\n",
    "    for image_file in Path(source_folder).rglob(\"*.bmp\"): # recursively find image paths\n",
    "        # Separate base from extension\n",
    "        base, extension = os.path.splitext(image_file.name)        \n",
    "        new_name = os.path.join(letter + \"_\" + str(ii) + extension)    \n",
    "        shutil.copy(image_file, Path(target_folder).joinpath(new_name))\n",
    "        img = tf.keras.utils.load_img(Path(target_folder).joinpath(new_name))\n",
    "        rotate = tfa.image.rotate(img, tf.random.uniform(shape = [], minval = -(RO_ANG), maxval = RO_ANG),'bilinear','constant',)\n",
    "        # img_cast = tf.cast(rotate,dtype=tf.uint8)\n",
    "        # img_4d = tf.expand_dims(img_cast, axis=0)\n",
    "        # img_res = tf.compat.v1.image.resize_bilinear(img_4d, (IMG_HEIGHT, IMG_WIDTH), align_corners=True)\n",
    "        img_encoded = tf.compat.v1.image.encode_png(tf.cast(rotate, tf.uint8))\n",
    "        # img_encoded = tf.compat.v1.image.encode_png(tf.cast(rotate, tf.uint16))\n",
    "        \n",
    "        extension ='.png'\n",
    "        rotate_name = os.path.join(letter + \"_r\" + str(ii) + extension)   \n",
    "        # print(rotate_name)\n",
    "        file = tf.compat.v1.write_file(str(Path(target_folder).joinpath(rotate_name)), img_encoded)     \n",
    "        # tfio.io.write_file(rotate_name, img_encoded)   \n",
    "        ii += 1\n",
    "\n",
    " \n",
    "OG_lettersInD = 'C:\\\\Users\\\\john\\\\Documents\\\\Arduino\\\\priWand\\\\letters\\\\'      \n",
    "destCollated = 'C:\\\\Users\\\\john\\\\Documents\\\\Arduino\\\\priWand\\\\priWand\\\\letters\\\\groupedWandLetters\\\\'  \n",
    "# destCollated = '..\\\\letters\\\\groupedWandLetters'  \n",
    "\n",
    "\n",
    "rootimage = OG_lettersInD\n",
    "disdir = destCollated     \n",
    "\n",
    "moveWandFiles(rootimage, disdir,letter)\n",
    "\n",
    "print(\"images collated and rotated\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "946deed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([13  3 15], shape=(3,), dtype=int64)\n",
      "Found 637 files belonging to 4 classes.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_LETTERS = 'LMCO'\n",
    "\n",
    "# Labels in the emnist/letters dataset that should be used for training.\n",
    "_LABELS = [ord(c) - ord('A') + 1 for c in _LETTERS ]\n",
    "labels = tf.constant(_LABELS, dtype=tf.int64)\n",
    "print(labels)\n",
    "\n",
    "# _WANTED_LABELS = [ord(c) - ord('A') + 1 for c in _LETTERS]\n",
    "# _OTHER_LABEL = 0\n",
    "# _NUM_CLASSES = len(_LETTERS) + 1  # All \"other\" letters classified as 0.\n",
    "\n",
    "\n",
    "        \n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    destCollated,\n",
    "    labels=\"inferred\",\n",
    "    # label_mode=\"int\",\n",
    "    # class_names=labels,\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=32,\n",
    "    image_size=(32, 32),\n",
    "    shuffle=False,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# RandomRotation is meant to be used as part of the network definition, and is only used during training and not evaluation. \n",
    "# factor=0.1\n",
    "# data_augmentation = tf.keras.Sequential([\n",
    "#     layers.experimental.preprocessing.RandomRotation(\n",
    "#         factor, interpolation='nearest',fill_mode = 'constant'),\n",
    "# ])\n",
    "\n",
    "\n",
    "\n",
    "# fill-mode = const: the input is extended by filling all values beyond the edge with the same constant value k = 0.\n",
    "\n",
    "# augmented_val_ds = val_ds.map(\n",
    "#     lambda x, y: (data_augmentation(x, training=True), y))\n",
    "\n",
    "\n",
    "\n",
    "# # Apply `data_augmentation` to the val images.\n",
    "# val_ds = val_ds.map(\n",
    "#     lambda img, label: (data_augmentation(img), label),\n",
    "#     num_parallel_calls=tf.data.AUTOTUNE,\n",
    "# )\n",
    "\n",
    "val_ds = val_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "pyplot.figure(figsize=(10, 10))\n",
    "for images, _ in val_ds.take(1):\n",
    "    for i in range(9):\n",
    "        # augmented_images = data_augmentation(images)\n",
    "        ax = pyplot.subplot(3, 3, i + 1)\n",
    "        pyplot.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        pyplot.axis(\"off\")\n",
    "    \n",
    "# pyplot.figure(figsize=(10, 10))\n",
    "# for images, _ in val_ds.take(1):\n",
    "#     for i in range(9):\n",
    "#         augmented_images = data_augmentation(images)\n",
    "#         ax = pyplot.subplot(3, 3, i + 1)\n",
    "#         pyplot.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "#         pyplot.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of letters we want to recognized\n",
    "_LETTERS = 'MOCL'\n",
    "# A set of letters used to train the \"other\" category. These shouldn't look\n",
    "# similar to any of the letters in _LETTERS\n",
    "_OTHER_LETTERS = 'FHIKRTY'\n",
    "\n",
    "\n",
    "# Labels in the emnist/letters dataset that should be used for training.\n",
    "_LABELS = [ord(c) - ord('A') + 1 for c in _LETTERS + _OTHER_LETTERS]\n",
    "\n",
    "_WANTED_LABELS = [ord(c) - ord('A') + 1 for c in _LETTERS]\n",
    "_OTHER_LABEL = 0\n",
    "_NUM_CLASSES = len(_LETTERS) + 1  # All \"other\" letters classified as 0.\n",
    "_BATCH_SIZE = 32\n",
    "\n",
    "# load train and test dataset\n",
    "\n",
    "\n",
    "\n",
    "def load_dataset():\n",
    "    # load dataset\n",
    "    (train_ds, test_ds), ds_info = tfds.load(\n",
    "        name='emnist/letters',\n",
    "        split=['train', 'test'],\n",
    "        shuffle_files=True,\n",
    "        with_info=True,\n",
    "        as_supervised=True,\n",
    "        decoders={\n",
    "            # Don't decode images, the dataset will get filtered,\n",
    "            # and we shouldn't decode what we don't use.\n",
    "            'image': tfds.decode.SkipDecoding(),\n",
    "        })\n",
    "\n",
    "    train_ds = prepare(train_ds, ds_info)\n",
    "    test_ds = prepare(test_ds, ds_info)\n",
    "\n",
    "    return (train_ds, test_ds), ds_info\n",
    "\n",
    "\n",
    "def prepare(dataset, ds_info):\n",
    "    labels = tf.constant(_LABELS, dtype=tf.int64)\n",
    "    wanted_labels = tf.constant(_WANTED_LABELS, dtype=tf.int64)\n",
    "\n",
    "    @tf.function\n",
    "    def is_wanted(image, label):\n",
    "        \"\"\"Returns true if label is in _LABELS\"\"\"\n",
    "        del image  # unused\n",
    "        return tf.math.reduce_any(label == labels)\n",
    "\n",
    "    @tf.function\n",
    "    def map_entry(image, label):\n",
    "        \"\"\"Transforms the image into the form our classifier will expect.\"\"\"\n",
    "        decoded = ds_info.features['image'].decode_example(image)\n",
    "        # Convert image to floats\n",
    "        image = tf.cast(decoded, tf.float32) / 255\n",
    "        # Images in emnist are transposed. Bring them back into normal direction.\n",
    "        image = tf.transpose(image, perm=[1, 0, 2])\n",
    "        label = tf.cond(\n",
    "            tf.math.reduce_any(label == wanted_labels),\n",
    "            # Relabel entries that are in _LETTERS to the range [1, len(_LETTERS)]\n",
    "            lambda: tf.argmax(tf.equal(wanted_labels, label)) + 1,\n",
    "            # Relabel entries in _OTHER_LETTERS to 0.\n",
    "            lambda: tf.constant(_OTHER_LABEL, dtype=tf.int64))\n",
    "        return image, label\n",
    "\n",
    "    return (dataset.filter(is_wanted).cache().shuffle(1000).map(\n",
    "        map_entry).batch(_BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "\n",
    "def define_model():\n",
    "    # Train with images that randomly rotated, in any direction. This is\n",
    "    # because we can't tell the direction the wand is held.\n",
    "    # If we could, we might get better classification by reducing the range of\n",
    "    # random rotation.\n",
    "    factor=0.2\n",
    "    data_augmentation = tf.keras.Sequential([\n",
    "        layers.experimental.preprocessing.RandomRotation(\n",
    "            factor, interpolation='nearest'),\n",
    "    ])\n",
    "    model = Sequential()\n",
    "    model.add(data_augmentation)\n",
    "    model.add(\n",
    "        layers.Conv2D(16, (3, 3),\n",
    "                      activation='relu',\n",
    "                      kernel_initializer='he_uniform',\n",
    "                      input_shape=(28, 28, 1)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(\n",
    "        layers.Conv2D(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      kernel_initializer='he_uniform'))\n",
    "    model.add(\n",
    "        layers.Conv2D(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      kernel_initializer='he_uniform'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(\n",
    "        layers.Dense(50, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(layers.Dense(_NUM_CLASSES))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# trains a model\n",
    "\n",
    "\n",
    "def train_model(train_ds, test_ds):\n",
    "    \"\"\"Trains the model, and outputs evaluation stats to TensorBoard.\"\"\"\n",
    "    model = define_model()\n",
    "    logs = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logs,\n",
    "                                                     histogram_freq=1,\n",
    "                                                     profile_batch='500,520')\n",
    "    # fit model\n",
    "    history = model.fit(train_ds,\n",
    "                        epochs=10,\n",
    "                        validation_data=test_ds,\n",
    "                        callbacks=[tboard_callback],\n",
    "                        class_weight=_label_weights(len(_LABELS),\n",
    "                                                    _WANTED_LABELS))\n",
    "    # evaluate model\n",
    "    _, acc = model.evaluate(test_ds)\n",
    "    print('> %.3f' % (acc * 100.0))\n",
    "    return model, acc, history\n",
    "\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "\n",
    "\n",
    "def summarize_diagnostics(histories):\n",
    "    for i in range(len(histories)):\n",
    "        # plot loss\n",
    "        pyplot.subplot(2, 1, 1)\n",
    "        pyplot.title('Cross Entropy Loss')\n",
    "        pyplot.plot(histories[i].history['loss'], color='blue', label='train')\n",
    "        pyplot.plot(histories[i].history['val_loss'],\n",
    "                    color='orange',\n",
    "                    label='test')\n",
    "        # plot accuracy\n",
    "        pyplot.subplot(2, 1, 2)\n",
    "        pyplot.title('Classification Accuracy')\n",
    "        pyplot.plot(histories[i].history['accuracy'],\n",
    "                    color='blue',\n",
    "                    label='train')\n",
    "        pyplot.plot(histories[i].history['val_accuracy'],\n",
    "                    color='orange',\n",
    "                    label='test')\n",
    "    pyplot.show()\n",
    "\n",
    "\n",
    "# summarize model performance\n",
    "\n",
    "\n",
    "def summarize_performance(scores):\n",
    "    # print summary\n",
    "    print('Accuracy: mean=%.3f std=%.3f, n=%d' %\n",
    "          (np.mean(scores) * 100, np.std(scores) * 100, len(scores)))\n",
    "    # box and whisker plots of results\n",
    "    pyplot.boxplot(scores)\n",
    "    pyplot.show()\n",
    "\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "\n",
    "\n",
    "def run_training():\n",
    "    \"\"\"Runs training and shows learning curves.\"\"\"\n",
    "    # load dataset\n",
    "    (train_ds, test_ds), ds_info = load_dataset()\n",
    "    # evaluate model\n",
    "    model, score, history = train_model(train_ds, test_ds)\n",
    "    # learning curves\n",
    "    summarize_diagnostics([history])\n",
    "    # summarize estimated performance\n",
    "    summarize_performance([score])\n",
    "    return model\n",
    "\n",
    "\n",
    "def _label_weights(total_num_labels, wanted_labels):\n",
    "    \"\"\"Reweight the label costs to account over represented OTHER label.\"\"\"\n",
    "    label_weights = {\n",
    "        l: 1.0 / (len(wanted_labels) + 1)\n",
    "        for l in range(len(wanted_labels) + 1)\n",
    "    }\n",
    "    label_weights[_OTHER_LABEL] = (1.0 /\n",
    "                                   ((len(wanted_labels) + 1) *\n",
    "                                    (total_num_labels - len(wanted_labels))))\n",
    "    return label_weights\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "\n",
    "def blur(img_array):\n",
    "    kernel = np.array([1, 3, 1])\n",
    "    img_array = np.apply_along_axis(\n",
    "        lambda x: np.convolve(x, kernel, mode='same'), 0, img_array)\n",
    "    img_array = np.apply_along_axis(\n",
    "        lambda x: np.convolve(x, kernel, mode='same'), 1, img_array)\n",
    "    return img_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = run_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=logs\n",
    "\n",
    "# python -m tensorboard.main --logdir=logs  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the model to tflite.\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "# open('model.tflite', 'wb').write(tflite_model)\n",
    "\n",
    "modelSaveName = _LETTERS + '_'+ _OTHER_LETTERS+'.tflite'\n",
    "open(modelSaveName, 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the tflite model\n",
    "\n",
    "\n",
    "interpreter = tf.lite.Interpreter(modelSaveName)\n",
    "# interpreter = tf.lite.Interpreter('model.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "input_tensor = interpreter.tensor(interpreter.get_input_details()[0][\"index\"])\n",
    "output_tensor = interpreter.tensor(interpreter.get_output_details()[0][\"index\"])\n",
    "def classify(letter_image):\n",
    "    input_tensor()[:] = letter_image\n",
    "    interpreter.invoke()\n",
    "    probabilities = softmax(output_tensor()[0])\n",
    "    index = np.argmax(probabilities)\n",
    "    if not index:\n",
    "        return 'UNKNOWN', probabilities[index]\n",
    "    return _LETTERS[index - 1],  probabilities[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the classifier on a few examples\n",
    "\n",
    "print('M letters')\n",
    "for i in range(3, 10):\n",
    "    image = Image.open(f\"evaluation/{i}_M.bmp\")\n",
    "    image = image.crop((0, 0, 28, 28))\n",
    "    np_image = np.array(image, np.float32)\n",
    "    np_image = np_image / 255.0\n",
    "    # Apply a blur to the input image to look more like the emnist training set.\n",
    "    np_image = blur(np_image)\n",
    "\n",
    "    pyplot.imshow(np_image, cmap='gray')\n",
    "    print(i, classify(np_image.reshape((1, 28, 28, 1))))\n",
    "    del image\n",
    "\n",
    "print('O letters')\n",
    "for i in range(3, 21):\n",
    "    image = Image.open(f\"evaluation/{i}_O.bmp\")\n",
    "    image = image.crop((0, 0, 28, 28))\n",
    "    np_image = np.array(image, np.float32)\n",
    "    np_image = np_image / 255.0\n",
    "    np_image = blur(np_image)\n",
    "    np_image = np_image / np.max(np_image)\n",
    "\n",
    "    pyplot.imshow(np_image, cmap='gray')\n",
    "    print(i, classify(np_image.reshape((1, 28, 28, 1))))\n",
    "    del image\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
