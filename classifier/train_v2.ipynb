{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying letters\n",
    "\n",
    "This notebook contains a training script for a classifier that can recognize a few letters from a bitmap.\n",
    "Version 2: uses data from the wand to validate (\"transfer learning\", if you will)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import pathlib\n",
    "import shutil\n",
    "from os import path\n",
    "from pathlib import Path\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dfbf34",
   "metadata": {},
   "source": [
    "create new dataset from wand drawn images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11540b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images collated\n"
     ]
    }
   ],
   "source": [
    "# first, copy all images of same class to single dir\n",
    "\n",
    "letter = 'M'       \n",
    "\n",
    "\n",
    "def moveWandFiles(source_folder:pathlib.Path, target_folder:pathlib.Path,letter):\n",
    "    target_folder= os.path.join(target_folder + letter )   \n",
    "    source_folder= os.path.join(source_folder + letter )   \n",
    "    Path(target_folder).mkdir(parents=True, exist_ok=True)\n",
    "    ii = 1\n",
    "    for image_file in Path(source_folder).rglob(\"*.bmp\"): # recursively find image paths\n",
    "        # Separate base from extension\n",
    "        base, extension = os.path.splitext(image_file.name)        \n",
    "        new_name = os.path.join(letter + \"_\" + str(ii) + extension)    \n",
    "        shutil.copy(image_file, Path(target_folder).joinpath(new_name))\n",
    "        ii += 1\n",
    "\n",
    "\n",
    "    \n",
    " \n",
    "OG_lettersInD = 'C:\\\\Users\\\\john\\\\Documents\\\\Arduino\\\\priWand\\\\letters\\\\'      \n",
    "destCollated = 'C:\\\\Users\\\\john\\\\Documents\\\\Arduino\\\\priWand\\\\priWand\\\\letters\\\\groupedWandLetters\\\\'  \n",
    "# destCollated = '..\\\\letters\\\\groupedWandLetters'  \n",
    "\n",
    "\n",
    "rootimage = OG_lettersInD\n",
    "disdir = destCollated     \n",
    "\n",
    "moveWandFiles(rootimage, disdir,letter)\n",
    "\n",
    "print(\"images collated\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "946deed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([12 13  3 15], shape=(4,), dtype=int64)\n",
      "Found 559 files belonging to 4 classes.\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "in user code:\n\n    C:\\Users\\john\\AppData\\Local\\Temp/ipykernel_14632/1965961158.py:39 None  *\n        lambda x, y: (data_augmentation(x, training=True), y)\n    C:\\Users\\john\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1030 __call__  **\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\john\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:394 call\n        outputs = layer(inputs, **kwargs)\n    C:\\Users\\john\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1030 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\john\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\layers\\preprocessing\\image_preprocessing.py:827 call\n        output = control_flow_util.smart_cond(training, random_rotated_inputs,\n    C:\\Users\\john\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\utils\\control_flow_util.py:109 smart_cond\n        return smart_module.smart_cond(\n    C:\\Users\\john\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\smart_cond.py:54 smart_cond\n        return true_fn()\n    C:\\Users\\john\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\layers\\preprocessing\\image_preprocessing.py:822 random_rotated_inputs\n        get_rotation_matrix(angles, img_hd, img_wd),\n    C:\\Users\\john\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\layers\\preprocessing\\image_preprocessing.py:729 get_rotation_matrix\n        array_ops.zeros((num_angles, 2), dtypes.float32),\n    C:\\Users\\john\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\john\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\array_ops.py:2911 wrapped\n        tensor = fun(*args, **kwargs)\n    C:\\Users\\john\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\array_ops.py:2960 zeros\n        output = _constant_if_small(zero, shape, dtype, name)\n    C:\\Users\\john\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\array_ops.py:2896 _constant_if_small\n        if np.prod(shape) < 1000:\n    <__array_function__ internals>:180 prod\n        \n    C:\\Users\\john\\AppData\\Roaming\\Python\\Python38\\site-packages\\numpy\\core\\fromnumeric.py:3088 prod\n        return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n    C:\\Users\\john\\AppData\\Roaming\\Python\\Python38\\site-packages\\numpy\\core\\fromnumeric.py:86 _wrapreduction\n        return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n    C:\\Users\\john\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py:867 __array__\n        raise NotImplementedError(\n\n    NotImplementedError: Cannot convert a symbolic Tensor (sequential_11/random_rotation_11/rotation_matrix/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14632/1965961158.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;31m# fill-mode = const: the input is extended by filling all values beyond the edge with the same constant value k = 0.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m augmented_val_ds = val_ds.map(\n\u001b[0m\u001b[0;32m     39\u001b[0m     lambda x, y: (data_augmentation(x, training=True), y))\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[0;32m   1923\u001b[0m         warnings.warn(\"The `deterministic` argument has no effect unless the \"\n\u001b[0;32m   1924\u001b[0m                       \"`num_parallel_calls` argument is specified.\")\n\u001b[1;32m-> 1925\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1926\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1927\u001b[0m       return ParallelMapDataset(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[0;32m   4481\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_use_inter_op_parallelism\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muse_inter_op_parallelism\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4482\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_preserve_cardinality\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4483\u001b[1;33m     self._map_func = StructuredFunctionWrapper(\n\u001b[0m\u001b[0;32m   4484\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4485\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m   3710\u001b[0m     \u001b[0mresource_tracker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtracking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mResourceTracker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3711\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3712\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3713\u001b[0m       \u001b[1;31m# There is no graph to add in eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3714\u001b[0m       \u001b[0madd_to_graph\u001b[0m \u001b[1;33m&=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3132\u001b[0m          \u001b[1;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3133\u001b[0m     \"\"\"\n\u001b[1;32m-> 3134\u001b[1;33m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0m\u001b[0;32m   3135\u001b[0m         *args, **kwargs)\n\u001b[0;32m   3136\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3098\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3099\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3100\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3101\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3102\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3444\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3277\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3278\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3279\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3280\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3281\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 999\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   3685\u001b[0m           attributes=defun_kwargs)\n\u001b[0;32m   3686\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=missing-docstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3687\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrapper_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3688\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3689\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   3615\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_should_unpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3616\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3617\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3618\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0m_should_pack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3619\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    693\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 695\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    696\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: in user code:\n\n    C:\\Users\\john\\AppData\\Local\\Temp/ipykernel_14632/1965961158.py:39 None  *\n        lambda x, y: (data_augmentation(x, training=True), y)\n    C:\\Users\\john\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1030 __call__  **\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\john\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:394 call\n        outputs = layer(inputs, **kwargs)\n    C:\\Users\\john\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1030 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\john\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\layers\\preprocessing\\image_preprocessing.py:827 call\n        output = control_flow_util.smart_cond(training, random_rotated_inputs,\n    C:\\Users\\john\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\utils\\control_flow_util.py:109 smart_cond\n        return smart_module.smart_cond(\n    C:\\Users\\john\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\smart_cond.py:54 smart_cond\n        return true_fn()\n    C:\\Users\\john\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\layers\\preprocessing\\image_preprocessing.py:822 random_rotated_inputs\n        get_rotation_matrix(angles, img_hd, img_wd),\n    C:\\Users\\john\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\layers\\preprocessing\\image_preprocessing.py:729 get_rotation_matrix\n        array_ops.zeros((num_angles, 2), dtypes.float32),\n    C:\\Users\\john\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\john\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\array_ops.py:2911 wrapped\n        tensor = fun(*args, **kwargs)\n    C:\\Users\\john\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\array_ops.py:2960 zeros\n        output = _constant_if_small(zero, shape, dtype, name)\n    C:\\Users\\john\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\array_ops.py:2896 _constant_if_small\n        if np.prod(shape) < 1000:\n    <__array_function__ internals>:180 prod\n        \n    C:\\Users\\john\\AppData\\Roaming\\Python\\Python38\\site-packages\\numpy\\core\\fromnumeric.py:3088 prod\n        return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n    C:\\Users\\john\\AppData\\Roaming\\Python\\Python38\\site-packages\\numpy\\core\\fromnumeric.py:86 _wrapreduction\n        return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n    C:\\Users\\john\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py:867 __array__\n        raise NotImplementedError(\n\n    NotImplementedError: Cannot convert a symbolic Tensor (sequential_11/random_rotation_11/rotation_matrix/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\n"
     ]
    }
   ],
   "source": [
    "_LETTERS = 'LMCO'\n",
    "\n",
    "# Labels in the emnist/letters dataset that should be used for training.\n",
    "_LABELS = [ord(c) - ord('A') + 1 for c in _LETTERS ]\n",
    "labels = tf.constant(_LABELS, dtype=tf.int64)\n",
    "print(labels)\n",
    "\n",
    "# _WANTED_LABELS = [ord(c) - ord('A') + 1 for c in _LETTERS]\n",
    "# _OTHER_LABEL = 0\n",
    "# _NUM_CLASSES = len(_LETTERS) + 1  # All \"other\" letters classified as 0.\n",
    "\n",
    "\n",
    "        \n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    destCollated,\n",
    "    labels=\"inferred\",\n",
    "    # label_mode=\"int\",\n",
    "    # class_names=labels,\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=32,\n",
    "    image_size=(30, 30),\n",
    "    shuffle=False,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    ")\n",
    "\n",
    "factor=0.1\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.experimental.preprocessing.RandomRotation(\n",
    "        factor, interpolation='nearest',fill_mode = 'constant'),\n",
    "])\n",
    "\n",
    "# fill-mode = const: the input is extended by filling all values beyond the edge with the same constant value k = 0.\n",
    "\n",
    "augmented_val_ds = val_ds.map(\n",
    "    lambda x, y: (data_augmentation(x, training=True), y))\n",
    "\n",
    "\n",
    "\n",
    "# Apply `data_augmentation` to the val images.\n",
    "val_ds = val_ds.map(\n",
    "    lambda img, label: (data_augmentation(img), label),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE,\n",
    ")\n",
    "\n",
    "val_ds = val_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "pyplot.figure(figsize=(10, 10))\n",
    "for images, _ in val_ds.take(1):\n",
    "    for i in range(9):\n",
    "        # augmented_images = data_augmentation(images)\n",
    "        ax = pyplot.subplot(3, 3, i + 1)\n",
    "        pyplot.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        pyplot.axis(\"off\")\n",
    "    \n",
    "pyplot.figure(figsize=(10, 10))\n",
    "for images, _ in val_ds.take(1):\n",
    "    for i in range(9):\n",
    "        augmented_images = data_augmentation(images)\n",
    "        ax = pyplot.subplot(3, 3, i + 1)\n",
    "        pyplot.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "        pyplot.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of letters we want to recognized\n",
    "_LETTERS = 'MOCL'\n",
    "# A set of letters used to train the \"other\" category. These shouldn't look\n",
    "# similar to any of the letters in _LETTERS\n",
    "_OTHER_LETTERS = 'FHIKRTY'\n",
    "\n",
    "\n",
    "# Labels in the emnist/letters dataset that should be used for training.\n",
    "_LABELS = [ord(c) - ord('A') + 1 for c in _LETTERS + _OTHER_LETTERS]\n",
    "\n",
    "_WANTED_LABELS = [ord(c) - ord('A') + 1 for c in _LETTERS]\n",
    "_OTHER_LABEL = 0\n",
    "_NUM_CLASSES = len(_LETTERS) + 1  # All \"other\" letters classified as 0.\n",
    "_BATCH_SIZE = 32\n",
    "\n",
    "# load train and test dataset\n",
    "\n",
    "\n",
    "\n",
    "def load_dataset():\n",
    "    # load dataset\n",
    "    (train_ds, test_ds), ds_info = tfds.load(\n",
    "        name='emnist/letters',\n",
    "        split=['train', 'test'],\n",
    "        shuffle_files=True,\n",
    "        with_info=True,\n",
    "        as_supervised=True,\n",
    "        decoders={\n",
    "            # Don't decode images, the dataset will get filtered,\n",
    "            # and we shouldn't decode what we don't use.\n",
    "            'image': tfds.decode.SkipDecoding(),\n",
    "        })\n",
    "\n",
    "    train_ds = prepare(train_ds, ds_info)\n",
    "    test_ds = prepare(test_ds, ds_info)\n",
    "\n",
    "    return (train_ds, test_ds), ds_info\n",
    "\n",
    "\n",
    "def prepare(dataset, ds_info):\n",
    "    labels = tf.constant(_LABELS, dtype=tf.int64)\n",
    "    wanted_labels = tf.constant(_WANTED_LABELS, dtype=tf.int64)\n",
    "\n",
    "    @tf.function\n",
    "    def is_wanted(image, label):\n",
    "        \"\"\"Returns true if label is in _LABELS\"\"\"\n",
    "        del image  # unused\n",
    "        return tf.math.reduce_any(label == labels)\n",
    "\n",
    "    @tf.function\n",
    "    def map_entry(image, label):\n",
    "        \"\"\"Transforms the image into the form our classifier will expect.\"\"\"\n",
    "        decoded = ds_info.features['image'].decode_example(image)\n",
    "        # Convert image to floats\n",
    "        image = tf.cast(decoded, tf.float32) / 255\n",
    "        # Images in emnist are transposed. Bring them back into normal direction.\n",
    "        image = tf.transpose(image, perm=[1, 0, 2])\n",
    "        label = tf.cond(\n",
    "            tf.math.reduce_any(label == wanted_labels),\n",
    "            # Relabel entries that are in _LETTERS to the range [1, len(_LETTERS)]\n",
    "            lambda: tf.argmax(tf.equal(wanted_labels, label)) + 1,\n",
    "            # Relabel entries in _OTHER_LETTERS to 0.\n",
    "            lambda: tf.constant(_OTHER_LABEL, dtype=tf.int64))\n",
    "        return image, label\n",
    "\n",
    "    return (dataset.filter(is_wanted).cache().shuffle(1000).map(\n",
    "        map_entry).batch(_BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "\n",
    "def define_model():\n",
    "    # Train with images that randomly rotated, in any direction. This is\n",
    "    # because we can't tell the direction the wand is held.\n",
    "    # If we could, we might get better classification by reducing the range of\n",
    "    # random rotation.\n",
    "    factor=0.2\n",
    "    data_augmentation = tf.keras.Sequential([\n",
    "        layers.experimental.preprocessing.RandomRotation(\n",
    "            factor, interpolation='nearest'),\n",
    "    ])\n",
    "    model = Sequential()\n",
    "    model.add(data_augmentation)\n",
    "    model.add(\n",
    "        layers.Conv2D(16, (3, 3),\n",
    "                      activation='relu',\n",
    "                      kernel_initializer='he_uniform',\n",
    "                      input_shape=(28, 28, 1)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(\n",
    "        layers.Conv2D(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      kernel_initializer='he_uniform'))\n",
    "    model.add(\n",
    "        layers.Conv2D(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      kernel_initializer='he_uniform'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(\n",
    "        layers.Dense(50, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(layers.Dense(_NUM_CLASSES))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# trains a model\n",
    "\n",
    "\n",
    "def train_model(train_ds, test_ds):\n",
    "    \"\"\"Trains the model, and outputs evaluation stats to TensorBoard.\"\"\"\n",
    "    model = define_model()\n",
    "    logs = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logs,\n",
    "                                                     histogram_freq=1,\n",
    "                                                     profile_batch='500,520')\n",
    "    # fit model\n",
    "    history = model.fit(train_ds,\n",
    "                        epochs=10,\n",
    "                        validation_data=test_ds,\n",
    "                        callbacks=[tboard_callback],\n",
    "                        class_weight=_label_weights(len(_LABELS),\n",
    "                                                    _WANTED_LABELS))\n",
    "    # evaluate model\n",
    "    _, acc = model.evaluate(test_ds)\n",
    "    print('> %.3f' % (acc * 100.0))\n",
    "    return model, acc, history\n",
    "\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "\n",
    "\n",
    "def summarize_diagnostics(histories):\n",
    "    for i in range(len(histories)):\n",
    "        # plot loss\n",
    "        pyplot.subplot(2, 1, 1)\n",
    "        pyplot.title('Cross Entropy Loss')\n",
    "        pyplot.plot(histories[i].history['loss'], color='blue', label='train')\n",
    "        pyplot.plot(histories[i].history['val_loss'],\n",
    "                    color='orange',\n",
    "                    label='test')\n",
    "        # plot accuracy\n",
    "        pyplot.subplot(2, 1, 2)\n",
    "        pyplot.title('Classification Accuracy')\n",
    "        pyplot.plot(histories[i].history['accuracy'],\n",
    "                    color='blue',\n",
    "                    label='train')\n",
    "        pyplot.plot(histories[i].history['val_accuracy'],\n",
    "                    color='orange',\n",
    "                    label='test')\n",
    "    pyplot.show()\n",
    "\n",
    "\n",
    "# summarize model performance\n",
    "\n",
    "\n",
    "def summarize_performance(scores):\n",
    "    # print summary\n",
    "    print('Accuracy: mean=%.3f std=%.3f, n=%d' %\n",
    "          (np.mean(scores) * 100, np.std(scores) * 100, len(scores)))\n",
    "    # box and whisker plots of results\n",
    "    pyplot.boxplot(scores)\n",
    "    pyplot.show()\n",
    "\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "\n",
    "\n",
    "def run_training():\n",
    "    \"\"\"Runs training and shows learning curves.\"\"\"\n",
    "    # load dataset\n",
    "    (train_ds, test_ds), ds_info = load_dataset()\n",
    "    # evaluate model\n",
    "    model, score, history = train_model(train_ds, test_ds)\n",
    "    # learning curves\n",
    "    summarize_diagnostics([history])\n",
    "    # summarize estimated performance\n",
    "    summarize_performance([score])\n",
    "    return model\n",
    "\n",
    "\n",
    "def _label_weights(total_num_labels, wanted_labels):\n",
    "    \"\"\"Reweight the label costs to account over represented OTHER label.\"\"\"\n",
    "    label_weights = {\n",
    "        l: 1.0 / (len(wanted_labels) + 1)\n",
    "        for l in range(len(wanted_labels) + 1)\n",
    "    }\n",
    "    label_weights[_OTHER_LABEL] = (1.0 /\n",
    "                                   ((len(wanted_labels) + 1) *\n",
    "                                    (total_num_labels - len(wanted_labels))))\n",
    "    return label_weights\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "\n",
    "def blur(img_array):\n",
    "    kernel = np.array([1, 3, 1])\n",
    "    img_array = np.apply_along_axis(\n",
    "        lambda x: np.convolve(x, kernel, mode='same'), 0, img_array)\n",
    "    img_array = np.apply_along_axis(\n",
    "        lambda x: np.convolve(x, kernel, mode='same'), 1, img_array)\n",
    "    return img_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "    142/Unknown - 3s 14ms/step - loss: 0.0718 - accuracy: 0.5720"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7336/2229346447.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7336/4181615935.py\u001b[0m in \u001b[0;36mrun_training\u001b[1;34m()\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mds_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[1;31m# evaluate model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m     \u001b[1;31m# learning curves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[0msummarize_diagnostics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7336/4181615935.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(train_ds, test_ds)\u001b[0m\n\u001b[0;32m    119\u001b[0m                                                      profile_batch='500,520')\n\u001b[0;32m    120\u001b[0m     \u001b[1;31m# fit model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m     history = model.fit(train_ds,\n\u001b[0m\u001b[0;32m    122\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = run_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=logs\n",
    "\n",
    "# python -m tensorboard.main --logdir=logs  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the model to tflite.\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "# open('model.tflite', 'wb').write(tflite_model)\n",
    "\n",
    "modelSaveName = _LETTERS + '_'+ _OTHER_LETTERS+'.tflite'\n",
    "open(modelSaveName, 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the tflite model\n",
    "\n",
    "\n",
    "interpreter = tf.lite.Interpreter(modelSaveName)\n",
    "# interpreter = tf.lite.Interpreter('model.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "input_tensor = interpreter.tensor(interpreter.get_input_details()[0][\"index\"])\n",
    "output_tensor = interpreter.tensor(interpreter.get_output_details()[0][\"index\"])\n",
    "def classify(letter_image):\n",
    "    input_tensor()[:] = letter_image\n",
    "    interpreter.invoke()\n",
    "    probabilities = softmax(output_tensor()[0])\n",
    "    index = np.argmax(probabilities)\n",
    "    if not index:\n",
    "        return 'UNKNOWN', probabilities[index]\n",
    "    return _LETTERS[index - 1],  probabilities[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the classifier on a few examples\n",
    "\n",
    "print('M letters')\n",
    "for i in range(3, 10):\n",
    "    image = Image.open(f\"evaluation/{i}_M.bmp\")\n",
    "    image = image.crop((0, 0, 28, 28))\n",
    "    np_image = np.array(image, np.float32)\n",
    "    np_image = np_image / 255.0\n",
    "    # Apply a blur to the input image to look more like the emnist training set.\n",
    "    np_image = blur(np_image)\n",
    "\n",
    "    pyplot.imshow(np_image, cmap='gray')\n",
    "    print(i, classify(np_image.reshape((1, 28, 28, 1))))\n",
    "    del image\n",
    "\n",
    "print('O letters')\n",
    "for i in range(3, 21):\n",
    "    image = Image.open(f\"evaluation/{i}_O.bmp\")\n",
    "    image = image.crop((0, 0, 28, 28))\n",
    "    np_image = np.array(image, np.float32)\n",
    "    np_image = np_image / 255.0\n",
    "    np_image = blur(np_image)\n",
    "    np_image = np_image / np.max(np_image)\n",
    "\n",
    "    pyplot.imshow(np_image, cmap='gray')\n",
    "    print(i, classify(np_image.reshape((1, 28, 28, 1))))\n",
    "    del image\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
